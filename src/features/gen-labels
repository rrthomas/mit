#!/usr/bin/python3
# Generate the specializer's labels file.
#
# Copyright (c) 2019 Mit authors
#
# The package is distributed under the MIT/X11 License.
#
# THIS PROGRAM IS PROVIDED AS IS, WITH NO WARRANTY. USE IS AT THE USER’S
# RISK.

import sys, json, pickle, re, functools, heapq

from mit_core.vm_data import Instruction
from futures import Future


if len(sys.argv) != 3:
    print("Usage: gen-labels PREDICTOR-FILENAME LABELS-FILENAME", file=sys.stderr)
    sys.exit(1)
predictor_filename = sys.argv[1]
labels_filename = sys.argv[2]

by_opcode = {i.opcode: i for i in Instruction}
with open(predictor_filename, 'rb') as f:
    # [{opcode (str): (new_state, count)]
    predictor = [
        {
            by_opcode[int(opcode, 16)]: (obj['new_state'], obj['count'])
            for opcode, obj in state.items()
        }
        for state in json.loads(f.read().decode())
    ]


class Distribution:
    '''
    Represents a frequency distribution over predictor states.
    Typically this represents some hypothetical situation.
    `NULL_HYPOTHESIS` is a Distribution covering all situations.
    The frequency of `state`, written `self[state]`, may be interpreted as
    the estimated number of times the state is visited and the hypothesis is
    true.

     - total - the sum of the frequencies of all the states.
    '''
    def __init__(self, iterable):
        '''
         - iterable - iterable of (state (int), frequency (float)).
           If a `state` is repeated, its `frequency`s will be summed.
        '''
        self.total = 0.
        self.frequencies = {}
        for state, frequency in iterable:
            assert type(state) is int and 0 <= state < len(predictor)
            assert type(frequency) is float and 0. <= frequency
            if state not in self.frequencies:
                self.frequencies[state] = 0.
            self.frequencies[state] += frequency
            self.total += frequency

    def __repr__(self):
        return 'Distribution({} states, total={})'.format(
            len(self.frequencies),
            self.total,
        )

    def __getitem__(self, state):
        '''Returns the frequency of `state` under this Distribution.'''
        assert type(state) is int and 0 <= state < len(predictor)
        return self.frequencies.get(state, 0.0)

    def predict(self):
        '''
        Returns a dict from Instruction to Distribution. Each entry gives
        a possible next Instruction and the Distribution that would result.
        The `total`s of the distributions give a frequency distribution over
        the Instructions.
        '''
        successors = {instruction: [] for instruction in Instruction}
        for state, frequency in self.frequencies.items():
            for instruction, (new_state, count) in predictor[state].items():
                probability = count / NULL_HYPOTHESIS[state]
                successors[instruction].append(
                    (new_state, frequency * probability)
                )
        return {
            instruction: Distribution(x)
            for instruction, x in successors.items()
        }

NULL_HYPOTHESIS = Distribution(
    (state, float(sum(count for _, count in transitions.values())))
    for state, transitions in enumerate(predictor)
)


# The set of Instructions that might modify the I register.
# We cannot guess beyond such an instruction.
GUESS_LIMITING = frozenset([
    Instruction.NEXT,
    Instruction.BRANCH,
    Instruction.BRANCHZ,
    Instruction.CALL,
])

class Path:
    '''
    Represents a sequence of instructions that has just been executed.

     - instructions - tuple of Instructions.
     - tos_constant - int - the constant value on the top of the stack, or
       `None` if unknown.
     - cached_depth - int - The number of topmost stack items that are cached
       at the end of this Path.
     - checked_depth - int - the number of empty stack slots that are known
       to exist above the topmost item at the end of this Path.
    '''
    def __init__(self, instructions):
        assert type(instructions) is tuple
        self.instructions = instructions
        self.tos_constant = None
        # Compute `tos_constant`, `cached_depth`, `checked_depth`.
        tos_constant = None
        cached_depth = 0
        checked_depth = 0
        for instruction in instructions:
            assert isinstance(instruction, Instruction)
            m = re.match('LIT_(\d+)', instruction.name)
            if m:
                # The last instruction exists and pushes a constant.
                tos_constant = int(m.group(1))
            elif instruction == Instruction.NEXT:
                pass
            else:
                tos_constant = None
            if instruction.args is None and instruction.results is None:
                # We know nothing after this instruction.
                cached_depth = 0
                checked_depth = 0
            else:
                # Simulate popping arguments.
                for item in reversed(instruction.args):
                    if item == 'ITEMS':
                        # Conservatively suppose `COUNT` is zero.
                        # We cannot cache items below 'ITEMS'.
                        cached_depth = 0
                    else:
                        cached_depth -= 1
                        checked_depth += 1
                if cached_depth < 0:
                    cached_depth = 0
                # Simulate pushing results.
                for item in instruction.results:
                    if item == 'ITEMS':
                        # Conservatively suppose `COUNT` is large.
                        checked_depth = 0
                        # We cannot cache items below 'ITEMS'.
                        cached_depth = 0
                    else:
                        cached_depth += 1
                        checked_depth -= 1
                if checked_depth < 0:
                    checked_depth = 0
        self.tos_constant = tos_constant
        self.cached_depth = cached_depth
        self.checked_depth = checked_depth

    def __repr__(self):
        return 'Path(({}))'.format(
            ', '.join(i.name for i in self.instructions)
        )

    def __eq__(self, other):
        return self.instructions == other.instructions

    def __hash__(self):
        return hash(self.instructions)

    def __len__(self):
        return len(self.instructions)

    def __getitem__(self, index_or_slice):
        if isinstance(index_or_slice, slice):
            return Path(self.instructions[index_or_slice])
        elif isinstance(index_or_slice, int):
            return self.instructions[index_or_slice]
        else:
            raise TypeError('Path indices must be integers or slices')

    def __add__(self, sequence):
        return Path(self.instructions + sequence)

    def is_useful_guess(self, instruction):
        '''
        Returns `True` if the implementation of `instruction` is significantly
        more efficient after executing this Path than from a standing start.
        '''
        if instruction.args is None or instruction.results is None:
            # Arbitrary stack effect. No optimizations are possible.
            return False
        elif 'ITEMS' in instruction.args or 'ITEMS' in instruction.results:
            # Variadic instruction. We can optimize only if we know `COUNT`.
            return (
                instruction.args[-1] == 'COUNT' and
                self.tos_constant is not None
            )
        else:
            # Ordinary instruction.
            return True

    def remove_repeating_part(self):
        '''
        If all of:
         - this Path ends with two repeats of some "loop body",
         - we know at least as much about the stack now as we did before
           the last repeat,
         - the last instruction is in `GUESS_LIMITING`,
        returns the Path before the last repeat, otherwise returns `self`.
        '''
        if len(self.instructions) < 2:
            return self
        if self.instructions[-1] not in GUESS_LIMITING:
            return self
        for n in range(2, len(self)//2+1):
            if self.instructions[-n:] == self.instructions[-2*n:-n]:
                shorter = self[:-n]
                if (self.cached_depth >= shorter.cached_depth and
                    self.checked_depth >= shorter.checked_depth
                ):
                    return shorter
        return self


@functools.total_ordering
class QueueItem:
    '''
    A potentially interesting Path and its resulting Distribution.
    Compares by `distribution.total` (reversed).
    '''
    def __init__(self, path, distribution):
        self.path = path
        self.distribution = distribution

    def __le__(self, other):
        return self.distribution.total.__ge__(other.distribution.total)

    def __eq__(self, other):
        return self.distribution.total.__eq__(other.distribution.total)

    def __hash__(self):
        return self.distribution.total.__hash__()

    def successors(self):
        '''Yields slightly longer paths.'''
        # Check for repetition.
        if self.path.remove_repeating_part() != self.path:
            # This path won't become a state, because we'll loop instead.
            return
        # Add one instruction to the Path in all useful ways.
        predictions = self.distribution.predict()
        for instruction, new_distribution in predictions.items():
            if self.path.is_useful_guess(instruction):
                yield QueueItem(
                    self.path + (instruction,),
                    new_distribution,
                )


print("Finding paths")

NUM_PATHS = 500

# The `NUM_PATHS` most common instruction sequences.
# Path -> frequency
language = {}

heap = [QueueItem(Path(()), NULL_HYPOTHESIS)]
for _ in range(NUM_PATHS):
    try:
        item = heapq.heappop(heap)
    except IndexError:
        break
    language[item.path] = item.distribution
    for new_item in item.successors():
        heapq.heappush(heap, new_item)

# Sanity check.

for path in language:
    assert path[:-1] in language

# For each path, find strings of instructions that might come next.

print("Choosing multi-guesses")

def elaborate_future(distribution, total):
    '''
    Returns a Future representing the Instructions predicted by
    `distribution`.
     - distribution - Distribution.
     - total - the frequency of the root of the decision tree. This is used
       to decide how deeply to elaborate the tree.
    '''
    children = {}
    for instruction, new_distribution in distribution.predict().items():
        if distribution.total + new_distribution.total < total:
            # Useless guess.
            pass
        elif instruction in GUESS_LIMITING:
            # Do not guess beyond this one.
            children[instruction] = Future(new_distribution.total, {})
        else:
            # Recurse.
            children[instruction] = elaborate_future(new_distribution, total)
    return Future(distribution.total, children)

# Path -> non-empty tuple of Instruction
path_guesses = {path: [] for path in language}

for path, distribution in language.items():
    future = elaborate_future(distribution, distribution.total)
    while True:
        guess = tuple(future.guess())
        if len(guess) == 0:
            break
        if path + guess not in language:
            break
        path_guesses[path].append(guess)
        future.eliminate(guess)

# Generate state space of (path × rejects) with flood fill.

print("Generating control flow graph")

states = [] # List of (Path, rejects)
state_index = {} # Inverse of `states`.

# For each state in `states`, there is a transition in `transitions`.
# It can be:
#  - None - goto fallback;
#  - int g - goto g;
#  - (tuple(Instruction) guess, int c, int w) -
#    if (next==guess) { execute guess; goto c; } else goto w;
transitions = []

def enqueue(path, rejects):
    '''
    Adds a state if it has not been seen before.
     - path - Path.
     - rejects - frozenset of tuples of Instructions.
    '''
    assert isinstance(path, Path)
    assert isinstance(rejects, frozenset)
    state = (path, rejects)
    if state not in state_index:
        state_index[state] = len(state_index)
        states.append(state)
    return state_index[state]

assert enqueue(Path(()), frozenset()) == 0 # Root state.

# The work queue is the suffix of `states` that does not yet have transitions.
while len(transitions) < len(states):
    path, rejects = states[len(transitions)]
    for guess in path_guesses[path]:
        if guess not in rejects:
            # We have a guess.
            successor = (path + guess).remove_repeating_part()
            new_rejects = rejects.union(
                guess[:l+1] for l in range(len(guess))
            )
            transitions.append((
                guess,
                enqueue(successor, frozenset()),
                enqueue(path, new_rejects),
            ))
            break
    else:
        # There is no good guess. Try again with a suffix of `path`.
        while len(path) > 0:
            path = path[1:]
            if path in language:
                transitions.append(enqueue(path, rejects))
                break
        else:
            # No more suffixes. Use the fallback executor.
            transitions.append(None)

assert len(states) == len(state_index) == len(transitions)

# Tension branches.

print("Tensioning branches")

# We only need labels for the states in which we make a guess.
label_map = {} # state -> label
for state, transition in enumerate(transitions):
    if isinstance(transition, tuple):
        label_map[state] = len(label_map)

def short_circuit(state):
    # Follows gotos, and maps `state` to a label or `None`.
    while isinstance(transitions[state], int):
        state = transitions[state]
    return label_map.get(state)

# List of (path properties... , guess, label or None, label or None).
labels = [
    (
        path.tos_constant,
        path.cached_depth,
        path.checked_depth,
        ' '.join(instruction.name for instruction in guess),
        short_circuit(c),
        short_circuit(w)
    )
    for (path, _), t in zip(states, transitions)
    if isinstance(t, tuple)
    for (guess, c, w) in [t]
]

assert len(label_map) == len(labels)

# Dump to a file.

with open(labels_filename, 'wb') as f:
    # [(
    #     tos_constant (int?),
    #     cached_depth (int),
    #     checked_depth (int),
    #     instruction_sequence (str, space-separated),
    #     if_correct (int?),
    #     if_wrong (int?)
    # )]
    pickle.dump(labels, file=f)
print('Wrote {}'.format(labels_filename))
