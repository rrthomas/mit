# Specialized interpreter Makefile.am
#
# (c) Mit authors 2019-2020
#
# The package is distributed under the MIT/X11 License.
#
# THIS PROGRAM IS PROVIDED AS IS, WITH NO WARRANTY. USE IS AT THE USERâ€™S
# RISK.

# The specialized interpreter is generated by `make specialize N=n`, which
# overwrites `specializer/profile.json` with an empty profile and then runs
# `repeat-specialize`. (To start with an existing profile, use `make
# respecialize` instead.) Typically, the first four to seven iterations
# improve performance significantly, but at least 20 iterations is
# recommended.

# `repeat-specializer` uses oprofile to measure the performance of each
# profile; oprofile requires Linux. It also needs the following kernel
# setting. As root, run: `echo 1 > /proc/sys/kernel/perf_event_paranoid`
#
# `configure.ac` contains code to detect the CPU type, which affects the
# name of the counter to use.

# `repeat-specialize` repeatedly performs the following steps:
#
# 1. Run `make specialize-once` to:
#
#  i. Profile some VM code with `mit_run_profile`. A profile records how
#     often each state in the current specialized interpreter was reached,
#     and how often the next state was correctly predicted.
#
# ii. Recursively call `make` to regenerate the specialized interpreter
#     using the new profile:
#
#   a. `labels.json` is built by `simulate-jit`, which reads a profile and
#      constructs a new control-flow graph for the specialized interpreter.
#
#   b. `specializer.c` is then generated by `gen-specializer`.
#
# 2. Compare the number of instructions executed (measured with `operf`)
# with the best so far. A copy of each profile produced is kept as
# `profile-N.json`.
#
# At the end, the best profile is copied to `profile.json`.

nodist_libmit_la_SOURCES += %D%/specializer.c

TEST_EXTENSIONS = .pforth
PFORTH_LOG_COMPILER = $(SHELL)
TESTS_ENVIRONMENT = \
	export abs_top_srcdir="$(abs_top_srcdir)" \
	export TIME_BINARY="$(TIME)"; \
	export MIT_BINARY="$(MIT_BINARY)";
bench:
	$(MAKE) check TESTS="$(BENCH_TESTS)"

if USING_PFORTH
specializer/pforth/src/highlevel.fs: specializer/pforth/config.status
specializer/pforth/config.status: specializer/pforth/configure
specializer/pforth/configure: specializer/pforth/configure.ac
	cd specializer/pforth && \
	autoreconf -i && \
	./configure --build=mit BUILD_EXECUTOR=$(MIT_BINARY)
check_DATA = specializer/pforth/src/highlevel.fs

TESTS = \
	%D%/build-pforth.pforth

BENCH_TESTS = \
	%D%/pforth-bench.pforth
endif

# Alternative profile-building arguments:
PROFILE_PFORTH_ARGS=make.fs
#PROFILE_PFORTH_ARGS=--evaluate BYE
#PROFILE_PFORTH_ARGS=tests.fs # (needs something on standard input)
specialize-once: mit@PACKAGE_SUFFIX@$(EXEEXT)
	export LD_LIBRARY_PATH=$(abs_top_builddir)/src/@objdir@:$(abs_top_builddir)/src/%D%/@objdir@:$$LD_LIBRARY_PATH; \
	cd %D%/pforth/src/mit && \
	$(abs_top_builddir)/python/mit-profile $(abs_builddir)/%D%/profile.json pforth $(PROFILE_PFORTH_ARGS) && \
	cd $(abs_builddir) && \
	$(MAKE)

%D%/labels.json: code_util.py params.py action.py spec.py %D%/profile.json %D%/simulate-jit %D%/path.py %D%/profile.py
	$(PYTHON_WITH_PATH) $(srcdir)/%D%/simulate-jit $(srcdir)/%D%/profile.json $@

%D%/specializer.c: code_util.py action.py stack.py spec.py run_fn.py %D%/specializer.am %D%/gen-specializer %D%/specializer.py %D%/specializer_spec.py %D%/labels.json
	$(PYTHON_WITH_PATH) $(srcdir)/%D%/gen-specializer %D%/labels.json > %D%/specializer.c || ( rm -f %D%/specializer.c; exit 1 )

%D%/specializer.lo: include/mit/mit.h

specialize:
	echo '[]' > %D%/profile.json; \
	$(MAKE) respecialize

respecialize: mit@PACKAGE_SUFFIX@$(EXEEXT)
	export MIT_BINARY=$(MIT_BINARY); \
	export TIME_BINARY="operf $(OPERF_OPTIONS)"; \
	$(PYTHON_WITH_PATH) $(srcdir)/specializer/repeat-specialize --times $(N)
	$(MAKE)

EXTRA_DIST += \
	%D%/path.py \
	%D%/profile.py \
	%D%/specializer_spec.py \
	%D%/specializer.py \
	%D%/simulate-jit \
	%D%/gen-specializer \
	%D%/repeat-specialize \
	%D%/profile.json

DISTCLEANFILES += \
	%D%/labels.json \
	%D%/specializer.c
